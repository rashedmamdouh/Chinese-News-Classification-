# ğŸ“° Chinese News Classification using BERT

This project demonstrates Chinese news article classification using a fine-tuned BERT model (`bert-base-chinese`) with Hugging Face's `transformers` library. The goal is to classify news articles into categories such as domestic, international, or general content.

---

## ğŸ“Œ Project Overview

- **Dataset:** Labeled Chinese news articles (`chinese_news.csv`)
- **Model:** `bert-base-chinese` fine-tuned using Hugging Face `Trainer`
- **Task:** Text classification with 3 classes:
  - `å›½å†… (Local)`
  - `å›½é™… (International)`
  - `è¯¦ç»†å…¨æ–‡ (General Article)`
- **Tools:** PyTorch, Transformers, Datasets, Scikit-learn, Pandas

---

## ğŸš€ Features

- End-to-end pipeline in a single Jupyter Notebook
- Tokenization using BERT tokenizer (handles Chinese)
- Automatic label encoding and mapping
- Train/Validation/Test split with evaluation metrics
- High classification accuracy (~92%)

---

## ğŸ“ Files

- `ChineseNewsClassifier.ipynb` â€“ Full code for preprocessing, training, evaluation, and prediction
- `README.md` â€“ Project documentation

> **Note:** The dataset file `chinese_news.csv` is assumed to be present locally. It is not included in the repo.

---

## ğŸ”§ Requirements

Install dependencies via:

```bash
pip install pandas scikit-learn matplotlib datasets transformers torch
````

---

## ğŸ“ˆ Results

* **Validation Accuracy:** \~92.4%
* **Test Accuracy:** \~92.7%
* **Model Output:** Predictions mapped to human-readable labels for interpretability

---

## âœ¨ Highlights

* Fine-tuned a BERT model on Chinese text for multi-class classification
* Used Hugging Face `Trainer` API for streamlined training
* Evaluated performance using accuracy and F1-score
* Output includes predicted vs true labels for test set
  
---

## ğŸ‘¨â€ğŸ’» Author

**Rashed Mamdouh**
AI Engineer â€” Arabic / English / ä¸­æ–‡ | NLP & Transformers
[GitHub](https://github.com/rashedmamdouh)

